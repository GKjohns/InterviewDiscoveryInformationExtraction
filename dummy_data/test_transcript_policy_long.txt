# thk-pol-476 (2024-10-21 16:45 GMT-4) - Transcript

## Attendees
Dr. Maya Krishnan (Senior Research Methodologist), Dr. James Barrett (Director of Climate Policy Research at Center for Future Policy)

## Transcript

Maya: Thank you for speaking with me today, Dr. Barrett. I'm particularly interested in understanding how research translates into actionable policy recommendations at your institution.

James: Thank you for having me. It's a critical question, especially given the current disconnect between research output and policy implementation in many areas.

Maya: Could you walk me through the lifecycle of how research findings become actionable recommendations?

James: Of course. Let me use our recent climate adaptation study as an example. We started with robust data on coastal flooding projections, but the challenge was translating that into implementable policy frameworks for local governments.

Maya: Could you elaborate on that translation process?

James: *referencing notes* The process typically involves multiple stages of synthesis. First, our research team produces what we call our "primary findings" - the raw analytical output. Then it goes through what we call our "policy visualization framework" where we map findings to existing policy structures and identify intervention points.

Maya: That's interesting. How do you determine which findings are actionable versus what might be more theoretical?

James: *thoughtfully* That's actually one of our biggest challenges. We use a three-tier system: immediate actionability, medium-term policy potential, and structural insights. For example, in our coastal study, immediate actionables were things like zoning recommendation changes, medium-term were infrastructure investment frameworks, and structural insights were about governance models for climate adaptation.

Maya: When you identify something as immediately actionable, what happens next?

James: We have a formalized process. Our policy translation team creates what we call "implementation pathways" - documents that outline the steps from current policy to recommended policy, including potential obstacles, stakeholder impacts, and resource requirements. But I'd say only about 20% of our research findings make it to this stage.

Maya: Why only 20%?

James: *adjusts glasses* Several factors. Sometimes the research, while valuable, doesn't have clear policy implications. Other times, the political economy makes implementation unfeasible in the current climate. And sometimes, we simply lack the institutional partnerships to move recommendations forward.

Maya: How do you evaluate whether research is having its intended impact?

James: We've developed a matrix for measuring research utilization. We track direct citations in policy documents, stakeholder engagement with our recommendations, and actual policy changes that align with our research. But I'll be honest - it's an imperfect science. Policy change is often incremental and attributing it to specific research is challenging.

Maya: Could you tell me about a time when research successfully led to policy change?

James: *nodding* Our work on urban heat islands led to significant changes in building codes in three major cities. What made it successful was that we created very specific, implementable recommendations: exact changes to building codes, cost-benefit analyses for different timeframes, and model legislation language. We essentially handed policymakers a complete package.

Maya: That's fascinating. How did you develop that approach?

James: Through years of failure, honestly. We used to produce brilliant research that sat on shelves. We learned that policymakers need more than just insights - they need tools for implementation. Now we have a standardized framework for what we call "policy-ready research."

Maya: Could you elaborate on this framework?

James: It's a six-part structure. Every major research project must include: one, the core findings; two, policy implications; three, implementation pathways; four, stakeholder impact analysis; five, resource requirements; and six, monitoring frameworks. We won't release research without all six components.

Maya: How do you handle situations where the research suggests policy changes that might be politically challenging?

James: *pauses* That's where our tiered implementation strategy comes in. We'll often break controversial recommendations into phases. We might start with pilot programs or voluntary adoption frameworks. We also spend considerable time on what we call "coalition mapping" - identifying potential allies and opponents for each recommendation.

Maya: How do you maintain research integrity while ensuring actionability?

James: *seriously* That's the core tension in our work. We have strict firewalls between our research and policy teams during the analysis phase. Only after findings are finalized does our policy team begin their work. We've found that if policy considerations influence research too early, it can create bias.

Maya: What about timing? How do you align research output with policy windows?

James: We maintain what we call a "policy calendar" - tracking legislative sessions, regulatory review periods, and other opportunities for policy intervention. We try to time our research release to align with these windows. But we've also learned to maintain "evergreen" recommendations that can be deployed when unexpected opportunities arise.

Maya: Could you talk about how you engage with policymakers during the research process?

James: It's a delicate balance. We have a stakeholder engagement protocol that allows for input on research questions and data sources, but maintains independence in analysis. We've found that early engagement increases the likelihood of implementation, but it has to be carefully managed.

Maya: How do you handle situations where new research contradicts previous policy recommendations?

James: *thoughtfully* That's become increasingly important, especially in rapidly evolving fields like climate science. We have a formal review process for our past recommendations. When new research contradicts previous positions, we issue what we call "policy update briefs" that explicitly address the changes and provide transition frameworks for policymakers who may have adopted our earlier recommendations.

Maya: How do you measure the quality of implementation when your recommendations are adopted?

James: We've developed what we call "fidelity metrics" - indicators that measure how closely implemented policies match our recommendations. But more importantly, we track outcomes. Are the policies achieving their intended effects? We maintain monitoring relationships with implementing agencies where possible.

Maya: What role does interdisciplinary research play in your policy recommendations?

James: *animatedly* It's become central to our work. We found that single-discipline approaches often missed critical implementation barriers. Now every major project has what we call "cross-cutting teams" - researchers from different disciplines who work together from day one. For example, our climate work combines climate science, economics, sociology, and public administration.

Maya: How do you handle uncertainty in research when making policy recommendations?

James: We use a structured uncertainty framework. Each recommendation includes what we call "confidence intervals" - not just statistical ones, but qualitative assessments of our certainty in different aspects of the recommendation. We're explicit about what we know, what we think we know, and what we're unsure about.

Maya: How do you build institutional capacity to act on research findings?

James: That's become a major focus recently. We've developed training modules for policy implementers, technical assistance programs, and what we call "policy learning networks" - groups of institutions working on similar implementations who can share experiences. We've found that capacity building is often as important as the research itself.

Maya: When research suggests the need for significant institutional change, how do you approach that?

James: *sighs* Those are our most challenging recommendations. We've developed what we call a "transformative change framework" - a structured approach to major institutional reforms. It includes change management protocols, transition planning, and risk mitigation strategies. But I'll be honest - these are the recommendations least likely to be fully implemented.

Maya: What about resource constraints? How do you handle situations where the best policy option isn't the most feasible?

James: We now include what we call "resource-scaled recommendations" - multiple versions of each recommendation calibrated to different resource levels. We're explicit about the trade-offs involved in each version. It's not ideal, but we've found that some implementation is often better than none.

Maya: This has been incredibly insightful. Is there anything else you'd like to add about the research-to-policy pipeline?

James: Just that we're constantly learning. The gap between research and implementation remains one of the biggest challenges in policy work. We're getting better at bridging it, but it requires constant innovation in how we structure and communicate our work.

Maya: Thank you so much for sharing your experiences and insights.

James: Thank you. These are critical questions for our field.

Meeting ended after 01:45:20

*This editable transcript was computer generated and might contain errors. People can also change the text after it was created.*